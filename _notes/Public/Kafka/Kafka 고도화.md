---
title: Kafka 파이프라인 고도화
feed: hide
date: 16-04-2025
permalink: /improve-kafka-pipeline
---


카프카 운영을 하면서 겪은 문제점들과 이를 해결하기 위해 여러 도구를 도입하고 고도화한 과정을 공유해보려고 합니다.

<br/>

Strimzi와 ksqlDB를 도입하여 파이프라인 유지보수성과 확장성을 높이고, 데이터 조직의 역할을 더 쉽고 넓게 가져갈 수 있게 했습니다.

기술적인 고민 뿐만아니라, 조직의 역할과 인터페이스에 대한 고민들이 있었기도 했고요.

지금은 이직하신 동료분과 함께 고민하던 일감인데, 올해 3월 초부터 진행하면서 무척 재미있었기에 블로그로 작성하게 되었습니다.

<br/>

이 글은 우선 기존 운영 환경의 모습을 설명하고, 문제를 제기하고, 해결하기 위한 방법과 기대 효과를 설명합니다.

디테일한 내용은 하위 링크의 별도 포스트로 작성할 예정입니다.

아직은 카프카 내에서 잘 모르는 디테일들이 많기때문에, 너그러이 봐주시면 감사드리겠습니다.


## 기존 운영 환경의 모습

일단, 기존에 카프카를 사용하던 방식을 먼저 설명드리겠습니다.

제가 속한 조직에서는 [[MSK]]를 기반으로 여러 개의 카프카 클러스터가 백엔드 개발 조직별로 나뉘어져 운영되고 있습니다.

타 개발 조직에서는 직접 프로듀서/컨슈머 코드를 작성하여 어플리케이션을 배포하는 경우가 많습니다.

<br/>

제가 속한 데이터 조직은 [cp-kafka-connect](https://hub.docker.com/r/confluentinc/cp-kafka-connect) 기반의 커넥트 클러스터를 구성해서 사용했었습니다.

프로듀서/컨슈머 어플리케이션 제작 없이 커넥터 기반으로만 데이터를 처리해왔습니다.

커넥터나 SMT 등 커넥터 실행에 필요한 빌드 아티팩트는 각 소스 레포지토리를 통해서 S3에 배포되어 있습니다.
커넥트 클러스터가 배포될 때 이 아티팩트들을 다운로드하는 구조입니다.

<br/>

이전까지의 카프카 파이프라인은 단순 추출 - 적재 파이프라인이였습니다.

주요 사용사례로
- 다른 카프카 토픽이나 데이터베이스 변경 사항을 수집
- 뭐든 그대로 빅쿼리로 적재

하는 파이프라인으로 구성되어 있었습니다.

배치 파이프라인에서는 빅쿼리와 dbt를 사용하고 있고, 필요한 경우 람다 아키텍쳐를 구성할 수 있었기 때문에 그간 실시간 처리의 중요성을 느끼지 못했습니다.


## 겪은 문제들과 원인

### 1. 커넥트 클러스터 형상 관리의 어려움
여러 Github 레포지토리에 분산된 S3에 아티팩트를 배포하는 파이프라인이 있습니다. 이 과정에서 여러 문제들이 발생했습니다:
- 각 카프카 클러스터별로 중복된 구성의 커넥터 클러스터를 유지해야 함
- 현재 각 커넥트 클러스터가 어떤 아티팩트들을 중심으로 배포되었는지 파악이 어려움
- 이로 인한 각 모듈 유지보수 및 업그레이드의 어려움

### 2. 수동 커넥터 배포의 한계
[kafbat-ui](https://ui.docs.kafbat.io/) 를 통해 수동 API 호출 방식으로 커넥터 배포를 진행하고 있었습니다. 이 방식도 여러 문제를 야기합니다:
- 휴먼 에러가 발생할 가능성이 높음
- 기록된 소스 코드 형상의 부재로 문제가 발생했을 때 원인 파악이 어려움
- 현재 배포된 커넥터의 형상 파악이 어려움
- 반복되는 설정의 복사/붙여넣기로 인해 실패 지점을 파악하기 어려움

### 3. 언급된 문제들로 인해 발생하는 하위 문제들
- 스트리밍 파이프라인의 관리 / 배포 어려움으로 "데이터 조직 = 집계 배치 처리 조직" 이라는 인식
- 배치 처리 기반으로 적절히 수행되는 데이터 엔지니어링 일감
- 인식으로 인해 제한되는 데이터 엔지니어의 역할과 일감

### 4. 전체 개발 조직내 실시간 집계 파이프라인의 부재
- 데이터 조직은, 앞서 말했듯이 집계 배치 처리 조직으로 인식되어 실시간 파이프라인의 개발 요청이 거의 없었습니다.
- 개발 조직은 데이터 처리방식에 대한 고민이 거의 없어서는
  - 복제 MySQL 데이터베이스에서 마이크로 배치 쿼리를 실행하거나 
  - 장기간 걸리는 쿼리를 구성하는 경우가 많았습니다
- 이로 인해 복제 데이터베이스의 요구 스펙이 올라가고, 많은 비용이 발생하기도 했습니다.
- 현재에도 이런식의 기술 부채가 남아 있습니다.

## 개선 포인트와 기대 효과

### [[Strimzi를 통한 커넥트 클러스터 및 커넥터 관리]]
우선 Strimzi를 사용해서 커넥트 클러스터를 구성하고 커넥터를 코드로 관리하는 방식으로 개선하고자 했습니다.

이를 진행하면서 커넥터나 SMT 같은 플러그인 빌드 아티팩트의 버전도 잘 관리할 수 있게 개선했습니다.

### [[ksqlDB를 통한 스트리밍 파이프라인 기능 추가]]
단순히 소스 / 싱크 커넥터를 운영하는 것만으로는 제한적인 운영을 할 수 밖에 없다고 판단해서 실시간 집계 도구가 필요했습니다.

<br/>

사실, 요즘은 실시간 집계 도구들로 ksqlDB가 아닌 Spark Streaming, RisingWave, Flink 같은 도구들이 자주 언급되는 것 같습니다.

심지어, ksqlDB를 소유하고 있는 Confluent는 2023년 Flink 회사인 Immerok를 인수하고 활발히 활동을 이어가고 있습니다.

<br/>

반면, ksqlDB는 기술적으로 미니멀하고 제한적인 부분들이 있었습니다.

게다가 카프카의 창시자중 한명이자 Confluent의 창업자인 제이 크랩스(Jay Kreps)도 [ksqlDB는 실패했다](https://x.com/jaykreps/status/1796992401791385640)고 말하기도 했습니다.

<br/>

이렇듯, ksqlDB는 실시간 집계처리로 사용하기에 한계점도 있고 외부 평가 역시 별로 좋지 않았습니다.

하지만 ksqlDB의 즉각적인 생산성과 직관성을 바탕으로, 조직 내에서 "이건 된다"라는 생각을 만들기에 빠르고 효과적일거라 기대했습니다.

우선 조직의 전반적인 인식을 바꿔야, 앞서 지적한 복제 데이터베이스 사용사례 같은 문제들이 해결될 수 있을거라 기대했습니다.